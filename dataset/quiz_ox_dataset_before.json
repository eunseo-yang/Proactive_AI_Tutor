{
  "learning_objectives": [
    "강화 학습(RL)이 무엇인지 정의하고, 머신러닝의 다른 분류 (지도 학습, 비지도 학습)와의 차이점을 이해한다.",
    "강화 학습 문제 설정 방법과 구성요소(에이전트, 환경, 상태, 행동, 보상)의 역할을 설명할 수 있다.",
    "전통적인 제어 방식과 강화 학습의 차이점과 유사점을 이해한다.",
    "가치 평가, 탐색(exploration)과 이용(exploitation) 개념 등을 이해하고 적용할 수 있다.",
    "탐색/이용 매개변수 및 미래 보상 할인 설정 등의 강화 학습의 세부 사항을 이해하고 조정할 수 있다."
  ],
  "quizzes": [
    {
      "id": 1,
      "objective_id": 1,
      "question": "강화학습은 에이전트가 환경과 상호작용하면서 학습하는 과정이다. (O/X)",
      "answer": "O",
      "explanation": "강화 학습은 에이전트가 환경과 상호작용하며 보상을 통해 최적의 행동을 배우는 과정을 말합니다."
    },
    {
      "id": 2,
      "objective_id": 1,
      "question": "강화 학습은 항상 정확한 답이 주어지고, 에이전트는 이 정답을 통해 학습하는 지도학습으로 볼 수 있다. (O/X)",
      "answer": "X",
      "explanation": "강화 학습은 정답 없이 보상을 통해 학습하는 방법으로, 시행착오를 통해 최적의 정책을 찾아냅니다."
    },
    {
      "id": 3,
      "objective_id": 1,
      "question": "강화 학습에서 에이전트는 미래의 가능한 모든 보상을 예측하여 현재의 최적 행동을 결정하는 알고리즘이다. (O/X)",
      "answer": "X",
      "explanation": "강화 학습에서 에이전트는 미래 보상을 고려하지만, 모든 가능성을 예측하기보다는 현재 정책에 따라 행동하고 결과에 따라 정책을 개선합니다. 완벽한 미래 예측은 불가능하며, 대신 추정과 근사를 통해 학습합니다."
    },
    {
      "id": 4,
      "objective_id": 2,
      "question": "보상은 강화학습에서 에이전트의 행동이 얼마나 좋은지를 평가하는 지표이다. (O/X)",
      "answer": "O",
      "explanation": "보상은 에이전트가 취한 행동에 대한 피드백으로, 에이전트가 얼마나 잘 행동했는지를 나타내는 지표입니다."
    },
    {
      "id": 5,
      "objective_id": 2,
      "question": "강화학습에서 행동은 환경에 의해 결정된다. (O/X)",
      "answer": "X",
      "explanation": "강화학습에서 행동은 에이전트에 의해 선택되며, 에이전트의 행동은 환경의 상태를 바탕으로 결정됩니다. 이 행동이 환경에 영향을 미칩니다."
    },
    {
      "id": 6,
      "objective_id": 2,
      "question": "강화 학습에서 에이전트의 상태는 시간에 따라 변할 수 있으며 완벽한 정보를 포함하고 있지 않아도 된다. (O/X)",
      "answer": "O",
      "explanation": "강화 학습에서 에이전트의 상태는 시간에 따라 변합니다. 에이전트가 환경과 상호작용하며 행동을 취할 때, 그 결과로 상태가 변하게 되며 이는 학습 과정에서 중요한 역할을 합니다. 또한 강화 학습에서 에이전트의 상태는 환경의 완벽한 정보를 포함할 필요는 없습니다. 상태는 에이전트가 관찰 가능한 환경의 일부 특성을 나타내며, 이는 완벽한 정보일 수도 있고 부분적인 정보일 수도 있습니다."
    },
    {
      "id": 7,
      "objective_id": 3,
      "question": "강화 학습의 최종 목표는 에이전트가 받을 수 있는 총 보상을 최대화하는 정책을 찾는 것이다. (O/X)",
      "answer": "O",
      "explanation": "강화 학습의 목표는 에이전트가 받을 수 있는 미래 보상의 합을 최대화하는 최적의 정책을 찾는 것입니다."
    },
    {
      "id": 8,
      "objective_id": 3,
      "question": "강화 학습에서 모든 행동이 동일한 보상을 받는다면, 에이전트는 더 이상 학습할 수 없다. (O/X)",
      "answer": "O",
      "explanation": "강화 학습에서 모든 행동이 동일한 보상을 받게 되면, 에이전트는 어떤 행동이 더 좋은지 구별할 수 없게 됩니다. 이는 학습 과정에 필요한 보상 기반 피드백이 부재함을 의미하며, 에이전트의 학습이 정체되어 더 이상의 학습이 이루어지지 않습니다."
    },
    {
      "id": 9,
      "objective_id": 3,
      "question": "강화학습에서 정책은 특정 상태에서 에이전트가 취할 행동의 확률을 정의하는 것이다. (O/X)",
      "answer": "O",
      "explanation": "정책은 각 상태에서 에이전트가 어떤 행동을 취할 확률을 매핑하는 함수로 정의됩니다."
    },
    {
      "id": 10,
      "objective_id": 3,
      "question": "강화 학습에서 정책 최적화는 에이전트가 환경과의 상호작용을 통해 점진적으로 이루어지며, 하나의 에피소드를 모두 돌면 학습이 종료된다. (O/X)",
      "answer": "X",
      "explanation": "정책 최적화는 여러 에피소드에 걸쳐 점진적으로 이루어지며, 에이전트는 경험을 통해 계속해서 학습하고 개선합니다. 하나의 에피소드가 끝났다고 해서 학습이 종료되는 것은 아닙니다."
    }
  ]
}
